{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "K6Tb0zQ3JnXQ",
    "outputId": "78026958-6aad-452a-98e1-2ebab21160fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images_train original shape (60000, 28, 28)\n",
      "Labels_train original shape (60000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "\n",
    "nb_classes = 10\n",
    "\n",
    "# the data, shuffled and split between tran and test sets\n",
    "(Images_train, Labels_train_orig), (Images_test, Labels_test_orig) = mnist.load_data()\n",
    "print(\"Images_train original shape\", Images_train.shape)\n",
    "print(\"Labels_train original shape\", Labels_train_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "GPIZLCNHJnXV",
    "outputId": "25c732f1-1dec-498b-b2fa-2de7737783e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training matrix shape (60000, 784)\n",
      "Testing matrix shape (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "#prepare the data. Matrix with each image in one row\n",
    "#<<<< Adaptar matriz de imágenes de train >>>>\n",
    "#<<<< Adaptar matriz de imágenes de test >>>>\n",
    "Images_train = Images_train.reshape((Images_train.shape[0], 28 * 28))\n",
    "Images_test = Images_test.reshape((Images_test.shape[0], 28 * 28))\n",
    "\n",
    "Images_train = Images_train.astype('float32')\n",
    "Images_test = Images_test.astype('float32')\n",
    "Images_train /= 255\n",
    "Images_test /= 255\n",
    "print(\"Training matrix shape\", Images_train.shape)\n",
    "print(\"Testing matrix shape\", Images_test.shape)\n",
    "\n",
    "#check input data is right\n",
    "assert Images_train.shape == (60000, 784), \"Train images. Wrong shape, try again\"\n",
    "assert Images_test.shape == (10000, 784), \"Test images. Wrong shape, try again\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jESWMaZaJnXZ"
   },
   "outputs": [],
   "source": [
    "#categorize, for instance, class 3 categorized to 0 0 0 1 0 0 0 0 0 0\n",
    "Labels_train = np_utils.to_categorical(Labels_train_orig, nb_classes)\n",
    "Labels_test = np_utils.to_categorical(Labels_test_orig, nb_classes)\n",
    "\n",
    "\n",
    "#model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "\tmetrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "UDzeqbmwJnXb",
    "outputId": "b8339e13-dd6d-4559-9b74-8e7c69b13fdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.8378 - acc: 0.7217 - val_loss: 0.2265 - val_acc: 0.9348\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.4628 - acc: 0.8582 - val_loss: 0.1601 - val_acc: 0.9542\n",
      "10000/10000 [==============================] - 0s 49us/step\n",
      "[0.1601157738186419, 0.9542]\n"
     ]
    }
   ],
   "source": [
    "model.fit(Images_train, Labels_train,\n",
    "          batch_size=128, epochs=2,\n",
    "          verbose=1,\n",
    "          validation_data=(Images_test, Labels_test))\n",
    "\n",
    "score = model.evaluate(Images_test, Labels_test,\n",
    "                       verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "gfDDVom3JnXf",
    "outputId": "9f1ba620-6f74-4181-bf8c-80f64e1e60f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9542,)\n",
      "(458,)\n"
     ]
    }
   ],
   "source": [
    "#Predict test images\n",
    "predicted_classes = model.predict_classes(Images_test)\n",
    "\n",
    "#Check correct and incorrect predictions\n",
    "correct_indices = np.nonzero(predicted_classes == Labels_test_orig)[0]\n",
    "print(correct_indices.shape)\n",
    "#<<<< Calcular los índices incorrectos >>>>\n",
    "#así podríamos ver las imágenes de los números en los que se equivoca\n",
    "wrong_indices = np.nonzero(predicted_classes != Labels_test_orig)[0]\n",
    "print(wrong_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gnUMUWe4JnXj",
    "outputId": "0e8720c1-ca73-4514-dfce-d9adc25e28b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(10)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#<<<< Calcular la precisión para cada clase. precisión = predicciones_correctas/total >>>>\n",
    "m = np.array(np.max(Labels_test_orig)+1, np.max(Labels_test_orig)+1)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yzXpzYUXJnXn",
    "outputId": "e0751a5c-2c18-4dd7-efde-948e665b67a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(Labels_test_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "colab_type": "code",
    "id": "_JlLsk5jJ1F-",
    "outputId": "1032abf9-bd25-4f6c-dd54-6d2d257b2804"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images_train original shape (60000, 28, 28)\n",
      "Labels_train original shape (60000,)\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "(28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngrADSRB2IAnCDiTx/wSyThk1bZlLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(Images_train, Labels_train_orig), (Images_test, Labels_test_orig) = mnist.load_data()\n",
    "print(\"Images_train original shape\", Images_train.shape)\n",
    "print(\"Labels_train original shape\", Labels_train_orig.shape)\n",
    "from keras import backend as K\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    Images_train = Images_train.reshape(Images_train.shape[0], 1, img_rows, img_cols)\n",
    "    Images_test = Images_test.reshape(Images_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    Images_train = Images_train.reshape(Images_train.shape[0], img_rows, img_cols, 1)\n",
    "    Images_test = Images_test.reshape(Images_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "Images_train = Images_train.astype('float32')\n",
    "Images_test = Images_test.astype('float32')\n",
    "Images_train /= 255\n",
    "Images_test /= 255\n",
    "print('x_train shape:', Images_train.shape)\n",
    "print(Images_train.shape[0], 'train samples')\n",
    "print(Images_test.shape[0], 'test samples')\n",
    "\n",
    "first_image = Images_test[4]\n",
    "print(first_image.shape)\n",
    "first_image = np.array(first_image, dtype='float')\n",
    "pixels = first_image.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "4-h-y0xPMpcj",
    "outputId": "cc1e3848-5e96-4134-b657-6a82d5f771f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_54 (Conv2D)           (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 120)               30840     \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 10)                1210      \n",
      "=================================================================\n",
      "Total params: 346,546\n",
      "Trainable params: 346,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LeNet 5\n",
    "#1st layer: 32,32,3 input\n",
    "#2nd layer: 28,28,6 conv 1\n",
    "#3rd layer: 14,14,6 pool 1\n",
    "#4rth layer: 10,10,16 conv2\n",
    "#5th layer : 5,5,16 pool 2 -> flatten\n",
    "#6th layer and beyond: use a standard deep network\n",
    "\n",
    "\n",
    "from keras import models, layers\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, kernel_size=(5, 5), strides=(1, 1), activation='relu', input_shape=(28, 28,1)))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "model.add(layers.Conv2D(64, kernel_size=(5, 5), strides=(1, 1), activation='relu', input_shape=(12, 12, 2)))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ul4y-wdYONc7"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "Tci474dnR6W7",
    "outputId": "71e82852-87ed-414b-922a-26a7626f765a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 59s 976us/step - loss: 0.0605 - acc: 0.9843 - val_loss: 0.0322 - val_acc: 0.9909\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 59s 981us/step - loss: 0.0527 - acc: 0.9869 - val_loss: 0.0317 - val_acc: 0.9912\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 59s 983us/step - loss: 0.0450 - acc: 0.9878 - val_loss: 0.0292 - val_acc: 0.9911\n",
      "10000/10000 [==============================] - 3s 313us/step\n",
      "[0.029186859695821295, 0.9911]\n"
     ]
    }
   ],
   "source": [
    "model.fit(Images_train, Labels_train,\n",
    "          batch_size=128, epochs=3,\n",
    "          verbose=1,\n",
    "          validation_data=(Images_test, Labels_test), shuffle = True)\n",
    "\n",
    "score = model.evaluate(Images_test, Labels_test,\n",
    "                       verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "PKy4NmohUm0o",
    "outputId": "d1e88a80-b9c2-4fd2-d8d7-a7928469ddc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9911,)\n",
      "(89,)\n"
     ]
    }
   ],
   "source": [
    "#Predict test images\n",
    "predicted_classes = model.predict_classes(Images_test)\n",
    "\n",
    "#Check correct and incorrect predictions\n",
    "correct_indices = np.nonzero(predicted_classes == Labels_test_orig)[0]\n",
    "print(correct_indices.shape)\n",
    "#<<<< Calcular los índices incorrectos >>>>\n",
    "#así podríamos ver las imágenes de los números en los que se equivoca\n",
    "wrong_indices = np.nonzero(predicted_classes != Labels_test_orig)[0]\n",
    "print(wrong_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QL9ZcHVxbPaa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copia de mnistNN_pract.ipynb",
   "provenance": []
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
